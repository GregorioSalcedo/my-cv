# URL <- "https://www.dropbox.com/s/tizgdsat2mziod6/medium-data-utf8.csv?dl=1"
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# URL <- "https://www.dropbox.com/s/tizgdsat2mziod6/medium-data-utf8.csv?dl=1"
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] )  pander()
library(dplyr)
library(stringr)
library(knitr)
library(pander)
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://www.dropbox.com/s/tizgdsat2mziod6/medium-data-utf8.csv?dl=1"
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://www.dropbox.com/s/tizgdsat2mziod6/medium-data-utf8.csv?dl=1"
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://www.dropbox.com/s/tizgdsat2mziod6/medium-data-utf8.csv?dl=1"
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
library(dplyr)
library(stringr)
library(knitr)
library(pander)
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$clap, main="Raw Clap Count",
xlim=c(1,950), breaks=5000, col="gray20", border="white" )
hist( log10(d$clap+1), main="Logged Clap Score",
col="gray20", border="white", breaks=100 )
d$clap.score <- log10( d$clap + 1 )
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
hist( d$clap, main="Raw Clap Count",
xlim=c(1,950), breaks=5000, col="gray20", border="white" )
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=5000, col="gray20", border="white" )
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$clap, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=5000, col="gray20", border="white" )
d$clap.score <- log10( d$claps + 1 )
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=50, col="gray20", border="white" )
d$clap.score <- log10( d$claps + 1 )
# Categorize titles
d$title_category <- case_when(
grepl("^[0-9]+\\s", d$title) ~ "Power List",
grepl("^(How to|How we)", d$title, ignore.case = TRUE) ~ "How-to Guide",
grepl(":.*", d$title) ~ "Colon Title",  # Contains a colon
grepl("\\?$", d$title) | grepl("^(Why|What|How|Can)\\s", d$title, ignore.case = TRUE) ~ "Question",
TRUE ~ "Other"
)
head(d[, c("title", "title_category")]) %>% pander()
# average clap score
avg_clap_scores <- d %>%
group_by(title_category) %>%
summarise(avg_clap_score = mean(clap.score, na.rm = TRUE)) %>%
arrange(desc(avg_clap_score))
avg_clap_scores %>% pander()
best_category <- avg_clap_scores %>% slice(1)
best_category
library(dplyr)
library(stringr)
library(knitr)
library(pander)
URL <- "https://raw.githubusercontent.com/DS4PS/cpp-527-fall-2020/master/labs/data/medium-data-utf8-v2.csv"
d <- read.csv( URL )
preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
head( d[preview.these] ) %>% pander()
# Remove extra spaces, HTML tags, and hair space dashes
d$title <- gsub("\\s+", " ", d$title)
d$title <- gsub("<[^>]+>", "", d$title)
d$title <- gsub("\u200A—\u200A", "", d$title)
head(d$title)
hist( d$claps, main="Raw Clap Count",
xlim=c(1,950), breaks=5000, col="gray20", border="white" )
#lowercase
d$title_clean <- tolower(d$title)
#split titles
word_list <- strsplit(d$title_clean, "\\s+")
#lowercase
d$title_clean <- tolower(d$title)
#split titles
word_list <- strsplit(d$title_clean, "\\s+")
word_list
#lowercase
d$title_clean <- tolower(d$title)
#split titles
word_list <- strsplit(d$title_clean, "\\s+")
head (word_list)
#get all words in one vector
all_words <- unlist(word_list)
# Remove punctuation
all_words <- gsub("[[:punct:]]", "", all_words)
# Count
word_freq <- table(all_words)
#top 25
top_25_words <- sort(word_freq, decreasing = TRUE)[1:25]
top_25_words %>% pander()
# extract first words
first_words <- sapply(word_list, function(x) x[1])
# count first word frequency
first_word_freq <- table(first_words)
# most common first word
most_common_first <- names(sort(first_word_freq, decreasing = TRUE))[1]
most_common_first
# Extract last words
last_words <- sapply(word_list, function(x) x[length(x)])
# Count last word frequency
last_word_freq <- table(last_words)
# most common last word
most_common_last <- names(sort(last_word_freq, decreasing = TRUE))[1]
most_common_last
quanteda.bundle <- c( "quanteda", "quanteda.textmodels",
"quanteda.textstats", "quanteda.textplots" )
install.packages( quanteda.bundle )
library( dplyr )
library( pander )
library( quanteda )
library( quanteda.textmodels )
quanteda.bundle <- c( "quanteda", "quanteda.textmodels",
"quanteda.textstats", "quanteda.textplots" )
install.packages( quanteda.bundle )
library( dplyr )
library( pander )
library( quanteda )
library( quanteda.textmodels )
quanteda.bundle <- c( "quanteda", "quanteda.textmodels",
"quanteda.textstats", "quanteda.textplots" )
install.packages( quanteda.bundle )
